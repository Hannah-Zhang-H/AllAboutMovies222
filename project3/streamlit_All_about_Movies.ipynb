{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "243c10bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 17:19:36.403 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# For movie type filter -> Han Zhang\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# for KNNregression -> Lei Liu\n",
    "from sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from wordcloud import WordCloud\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "import altair_viewer\n",
    "\n",
    "\n",
    "# Data and plots -> Jie Chang\n",
    "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
    "# Import the drawtree map package\n",
    "import squarify\n",
    "\n",
    "# content:\n",
    "def main():\n",
    "    # set title\n",
    "    st.title(\"All about Movies\")\n",
    "    \n",
    "#     # set password\n",
    "#     password_check = st.text_input(\"Please enter your password\")\n",
    "#     if password_check != st.secrets['password']:\n",
    "#         st.stop()\n",
    "    st.markdown(\"<h2 style='color:green;font-size:24px;'>Amazing movie data analysis</h2>\", unsafe_allow_html=True)    \n",
    "#     st.subheader(\"Amazing movie data analysis\")\n",
    "    # set pic\n",
    "    #     image = Image.open('/Users/hanhan/project3/headerPic.png')\n",
    "#     st.image(image)\n",
    "    st.image('headerPic.png')\n",
    "    \n",
    "    \n",
    "#     ################################################################################# \n",
    "    \n",
    "#                                     # Jie Chang\n",
    "        \n",
    "#     ################################################################################# \n",
    "\n",
    "    st.image('JieBackground.jpeg', width = 800)\n",
    "    st.header(\"Jie Chang\")\n",
    "#     # 1. Data scrapping\n",
    "#     # header\n",
    "    st.header('Data')\n",
    "    st.subheader('Web Scratching')\n",
    "    code = \"\"\"\"\n",
    "    from selenium import webdriver\n",
    "    from lxml import etree\n",
    "    import time\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.common.action_chains import ActionChains\n",
    "    import random\n",
    "    from  openpyxl import  Workbook \n",
    "    driver_path = \"chromedriver.exe\"\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    \n",
    "    # Instantiate a startup parameter object.\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('blink-settings=imagesEnabled=false') \n",
    "    chrome_options.add_argument('--disable-infobars')\n",
    "    driver = webdriver.Chrome(executable_path=driver_path,chrome_options=chrome_options)\n",
    "\n",
    "    for year in range(2010,2022):\n",
    "    root_url = f\"https://www.the-numbers.com/box-office-records/worldwide/all-movies/cumulative/released-in-{str(year)}\"\n",
    "    driver.get(root_url)\n",
    "    tabs = driver.find_elements(By.XPATH,\"//div[@class='pagination']/a\")\n",
    "    urls = [tab.get_attribute('href') for tab in tabs]\n",
    "    name_url = {}\n",
    "    first_list = []\n",
    "    for url in urls:\n",
    "        driver.get(url)\n",
    "        titles = driver.find_elements(By.XPATH,\"//div[@id='page_filling_chart']//table/thead/tr/th\")\n",
    "        tt = [ title.text for title in titles]\n",
    "        rows =  driver.find_elements(By.XPATH,\"//div[@id='page_filling_chart']//table/tbody/tr\")\n",
    "        for row in rows:\n",
    "            datas = row.find_elements(By.XPATH,\"./td\")\n",
    "            a_url = row.find_element(By.XPATH,\"./td//a\").get_attribute('href')\n",
    "            r_data = [data.text for data in datas]\n",
    "            first_list.append(r_data)\n",
    "            name_url[r_data[1]] = a_url\n",
    "            \n",
    "    # subpage\n",
    "    second_title = ['Domestic Releases:','Production Budget:','Theater counts:','Running Time:','Keywords:','Genre:','Production Countries:','Languages:']\n",
    "    second_dic = {}\n",
    "    for name,n_url in name_url.items():\n",
    "        driver.get(n_url) \n",
    "        second_dic[name] = ['']*len(second_title)\n",
    "        trs = driver.find_elements(By.XPATH,\"//div[@class='content active']/table//tr\")\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_elements(By.XPATH,\"./td\")\n",
    "            if len(tds) == 2:\n",
    "                if tds[0].text in second_title:\n",
    "                    second_dic[name][second_title.index(tds[0].text)] = tds[1].text\n",
    "    for i in range(len(first_list)):\n",
    "        first_list[i].extend(second_dic[first_list[i][1]])\n",
    "        \n",
    "    \n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    tt.extend(second_title)\n",
    "    ws.append(tt)\n",
    "\n",
    "    for row in first_list:\n",
    "        ws.append(row)\n",
    "    wb.save(f\"movies{year}.xlsx\")\n",
    "    \n",
    "    root_url = f\"https://www.the-numbers.com/box-office-records/worldwide/all-movies/cumulative/released-in-2022\"\n",
    "    driver.get(root_url)\n",
    "    tabs = driver.find_elements(By.XPATH,\"//div[@class='pagination']/a\")\n",
    "    urls = [tab.get_attribute('href') for tab in tabs]\n",
    "    name_url = {}\n",
    "    first_list = []\n",
    "    for url in urls:\n",
    "        driver.get(url)\n",
    "        titles = driver.find_elements(By.XPATH,\"//div[@id='page_filling_chart']//table/thead/tr/th\")\n",
    "        tt = [ title.text for title in titles]\n",
    "        rows =  driver.find_elements(By.XPATH,\"//div[@id='page_filling_chart']//table/tbody/tr\")\n",
    "        for row in rows:\n",
    "            datas = row.find_elements(By.XPATH,\"./td\")\n",
    "            a_url = row.find_element(By.XPATH,\"./td//a\").get_attribute('href')\n",
    "            r_data = [data.text for data in datas]\n",
    "            first_list.append(r_data)\n",
    "            name_url[r_data[1]] = a_url\n",
    "            \n",
    "    # subpage\n",
    "    second_title = ['Domestic Releases:','Production Budget:','Theater counts:','Running Time:','Keywords:','Genre:','Production Countries:','Languages:']\n",
    "    second_dic = {}\n",
    "    for name,n_url in name_url.items():\n",
    "        driver.get(n_url) \n",
    "        second_dic[name] = ['']*len(second_title)\n",
    "        trs = driver.find_elements(By.XPATH,\"//div[@class='content active']/table//tr\")\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_elements(By.XPATH,\"./td\")\n",
    "            if len(tds) == 2:\n",
    "                if tds[0].text in second_title:\n",
    "                    second_dic[name][second_title.index(tds[0].text)] = tds[1].text\n",
    "    for i in range(len(first_list)):\n",
    "        first_list[i].extend(second_dic[first_list[i][1]])\n",
    "\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    tt.extend(second_title)\n",
    "    ws.append(tt)\n",
    "\n",
    "    for row in first_list:\n",
    "        ws.append(row)\n",
    "    wb.save(\"movies2022.xlsx\")\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    st.code(code, language='python')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    st.subheader('Data Wrangling')\n",
    "    code1 = \"\"\"\n",
    "    file_paths = glob.glob('*.xlsx')\n",
    "    merged_data = pd.DataFrame()\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_excel(file_path)\n",
    "        merged_data = pd.concat([merged_data, df], ignore_index=True)\n",
    "    \n",
    "    # movie budget \n",
    "    import re\n",
    "    pattern = r'\\(.*?\\)'\n",
    "    merged_data['Production Budget:'] = [re.sub(pattern, '', str(string)) for string in merged_data['Production Budget:']]\n",
    "    \n",
    "    # Movie theater broadcast volume cleaning, including the number of movie theaters and the number of playing weeks\n",
    "    merged_data['Opening_theaters'] = merged_data['Theater counts:'].str.extract(r'([\\d,]+) opening theaters')\n",
    "    merged_data['Max_theaters'] = merged_data['Theater counts:'].str.extract(r'([\\d,]+) max\\. theaters')\n",
    "    merged_data['Average_run(week)'] = merged_data['Theater counts:'].str.extract(r'([\\d.]+) weeks average run per theater')\n",
    "    \n",
    "    # Extract showtimes\n",
    "    merged_data['Domestic Releases:'] = merged_data['Domestic Releases:'].str.extract(r'(.*?)\\s*\\(', expand=False)\n",
    "    \n",
    "    # delect some column which I don't use\n",
    "    merged_data= merged_data.drop('Theater counts:',axis=1)\n",
    "    \n",
    "    # change data type\n",
    "    merged_data['Average_run(week)'] = merged_data['Average_run(week)'].astype(float)\n",
    "    merged_data['Max_theaters'] = merged_data['Max_theaters'].str.replace(',', '').fillna(0).astype(int)\n",
    "    merged_data['Opening_theaters'] = merged_data['Opening_theaters'].astype(str)\n",
    "    merged_data['Running Time:'] = merged_data['Running Time:'].str.replace(' minutes', '').fillna(0).astype(int)\n",
    "    merged_data['Production Budget:'] = merged_data['Production Budget:'].str.replace('$', '',regex=True).str.replace(',', '',regex=True).replace('nan', np.nan,regex=True)\n",
    "    merged_data['Production Budget:'] =merged_data['Production Budget:'].fillna(0).astype(int)\n",
    "    merged_data['Worldwide Box Office'] = merged_data['Worldwide Box Office'].str.replace('$', '',regex=True).str.replace(',', '',regex=True).replace('nan', np.nan,regex=True).fillna(0)\n",
    "    merged_data['Worldwide Box Office']=merged_data['Worldwide Box Office'].astype(float)\n",
    "    merged_data['Domestic Box Office'] = merged_data['Domestic Box Office'].str.replace('$', '',regex=True).str.replace(',', '',regex=True).astype(float).fillna(0)\n",
    "    merged_data['Domestic Box Office'] = merged_data['Domestic Box Office'].astype(int)\n",
    "    merged_data['International Box Office'] = merged_data['International Box Office'].str.replace('$', '',regex=True).str.replace(',', '',regex=True).replace('nan', np.nan,regex=True).fillna(0).astype(int)\n",
    "    merged_data['Domestic\\nShare'] = merged_data['Domestic\\nShare'].str.strip('%').astype(float) / 100\n",
    "    merged_data.columns = merged_data.columns.str.replace(':', '',regex=True)\n",
    "    merged_data.rename(columns={'Domestic Releases': 'Date'}, inplace=True)\n",
    "    merged_data.to_csv('wrangling_data.csv', index=False)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    st.code(code1, language='python')\n",
    "    \n",
    "\n",
    "    ## data processing and plotting\n",
    "    st.subheader('Plotting')\n",
    "        # upload movie csv\n",
    "    uploader_file3 = st.file_uploader(\n",
    "        label = \"Upolad your dataset\"\n",
    "        , key=\"uploader3\"\n",
    "    )\n",
    "    \n",
    "    data3 = None \n",
    "    \n",
    "   # if the file is uploaded successfully, then go to train model\n",
    "    if uploader_file3 is None:\n",
    "     # if file is empty, display: please upload file\n",
    "        st.error(\"Please upload a file！\")\n",
    "        return\n",
    "\n",
    "    else:\n",
    "        st.success('Successfully uploaded!')\n",
    "        data3 = pd.read_csv(uploader_file3)\n",
    "        data3.dropna(inplace=True)\n",
    "        \n",
    "        \n",
    "    # data processing\n",
    "    # Clean out the data rows with null values directly, and the result shows that there are 1998 rows left\n",
    "    data3 = data3.dropna(how='any')\n",
    "    data3.Date = data3.Date.str.replace(' ', '/',regex=True).str.replace(',', '',regex=True)\n",
    "    data3.Date = data3.Date.str.replace(\"th\", \"\")\n",
    "    data3.Date = data3.Date.str.replace(\"st\", \"\")\n",
    "    data3.Date = data3.Date.str.replace(\"nd\", \"\")\n",
    "    data3.Date = data3.Date.str.replace(\"rd\", \"\")\n",
    "    data3['Date'] = data3['Date'].str.split('/').str[0].str[:3]+'/'+data3['Date'].str.split('/').str[1]+'/'+data3['Date'].str.split('/').str[2]\n",
    "    data3 = data3.dropna(subset=\"Date\")\n",
    "    data3.Date = pd.to_datetime(data3.Date,format=\"%b/%d/%Y\")\n",
    "    data3['Year'] = data3['Date'].dt.year\n",
    "    \n",
    "    # create figure\n",
    "    # figure 1\n",
    "    st.write('fig 1 - Movie by Year')\n",
    "    movie_years_count = data3.groupby('Year')['Movie'].count()\n",
    "    plt.figure(figsize=(10, 8), dpi=80)\n",
    "    movie_years_count.plot()\n",
    "    plt.title('Movie by Year', fontsize=12)\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Count')\n",
    "    st.pyplot()\n",
    "    \n",
    "    # description\n",
    "    st.write(\"\"\"\n",
    "    Description:\n",
    "    \n",
    "    Here I use the groupby statement to directly group the target label items, and count() is an aggregation function to summarize the statistics of the movie\n",
    "    \n",
    "    It can be seen that the number of movies has dropped sharply after 2018, and it is guessed that the reason is due to the covid-19\n",
    "    \n",
    "    \n",
    "    \"\"\")\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # Movie box office trends over the years\n",
    "    st.write('fig 2 - Movie box office trends over the years')\n",
    "    movie_gross = data3.groupby('Year')['Worldwide Box Office'].sum()\n",
    "    fig, ax = plt.subplots(figsize=(10, 8), dpi=80)\n",
    "    x = movie_gross.index.tolist()\n",
    "    y = movie_gross.values\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(x)))\n",
    "    ax.bar(x, y, color=colors)\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        ax.text(x[i], y[i]+0.05, '%i' % y[i], ha='center', va='bottom', rotation=45)\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('World Box Office')\n",
    "    ax.set_title('World Box Office by Year')\n",
    "    st.pyplot(fig)\n",
    "    st.write(\"\"\"\n",
    "    Description:\n",
    "    \n",
    "    It is evident that the global movie box office experienced a sharp decline starting from the outbreak of the pandemic in 2019. However,\n",
    "    after the end of the pandemic in 2021, there has been a gradual\n",
    "    recovery in box office revenue.\n",
    "    \n",
    "    \n",
    "    \"\"\")\n",
    "    \n",
    "    \n",
    "    # 'Worldwide Box Office by Average run(week)\n",
    "    st.write('fig 3 - Worldwide Box Office by Average run(week)')\n",
    "    run_week_count = data3.groupby('Average_run(week)')['Worldwide Box Office'].count()\n",
    "    fig, ax = plt.subplots()\n",
    "    run_week_count.plot(ax=ax)\n",
    "    ax.set_title('Worldwide Box Office by Average run(week)', fontsize=12)\n",
    "    ax.set_xlabel('Average run(week)')\n",
    "    ax.set_ylabel('Count')\n",
    "    st.pyplot(fig)\n",
    "    st.write(\"\"\"\n",
    "    Description:\n",
    "    \n",
    "    Let's analyze the impact of the number of weeks a movie is screened on its box office \n",
    "    performance. We can observe that initially, the box office revenue tends to \n",
    "    increase with the number of weeks a movie is screened. However, after around 8 weeks \n",
    "    of screening, the impact on the box office revenue becomes less significant.\n",
    "\n",
    "\n",
    "    \"\"\")\n",
    "    \n",
    "    \n",
    "    # Distribution of Movie Genres\n",
    "    st.write('fig 4 - Distribution of Movie Genres')\n",
    "    movie_type = data3['Genre'].str.split('/')\n",
    "    # Convert List to Series\n",
    "    movie_type = movie_type.apply(pd.Series)\n",
    "    # Use the unstack function to rotate rows into columns and rearrange data:\n",
    "    movie_type = movie_type.apply(pd.value_counts)\n",
    "    # At this time, the data is a Series, remove the null value, and convert it to Dataframe by reset_index()\n",
    "    movie_type = movie_type.unstack().dropna().reset_index()\n",
    "    # Summary of movie genres\n",
    "    movie_type.columns =['level_0','type','counts']\n",
    "    amovie_type_m = movie_type.drop(['level_0'],axis=1).groupby('type').sum().sort_values(by=['counts'],ascending=False).reset_index()\n",
    "    size = [1100, 900, 759, 416, 323, 300, 286, 180, 148, 136, 128, 105, 104, 103, 92]\n",
    "    name = ['Drama', 'Action', 'Adventure', 'Comedy', 'Suspense', 'Thriller', 'Horror', 'Romantic Comedy',\n",
    "            'Black Comedy', 'Documentary', 'Musical', 'Western', 'Concert', 'Performance', 'Multiple Genres', 'Reality']\n",
    "    colors = ['steelblue', '#9999ff', 'red', 'indianred', 'green', 'yellow', 'orange']\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    squarify.plot(\n",
    "        sizes=size,\n",
    "        color=colors,\n",
    "        label=name,\n",
    "        value=size,\n",
    "        alpha=0.5,\n",
    "        edgecolor='white',\n",
    "        linewidth=3,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    plt.rc('font', size=7)\n",
    "    ax.set_title('Distribution of Movie Genres', fontdict={'fontsize': 20})\n",
    "    ax.axis('off')\n",
    "    ax.tick_params(top='off', right='off')\n",
    "\n",
    "    st.pyplot(fig)\n",
    "    \n",
    "    \n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('========================================================================================')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ################################################################################# \n",
    "    \n",
    "                                # Han Zhang\n",
    "\n",
    "    ################################################################################# \n",
    "    \n",
    "    st.image('HanBackground.webp')\n",
    "    st.header('Han Zhang')\n",
    "    # 1. film filter model\n",
    "    # header\n",
    "    st.header('Movie Types')\n",
    "    \n",
    "    # upload movie csv\n",
    "    uploader_file = st.file_uploader(\n",
    "        label = \"Upolad your dataset\"\n",
    "        , key=\"uploader1\"\n",
    "    )\n",
    "    \n",
    "    input_df = None \n",
    "    \n",
    "   # if the file is uploaded successfully, then go to train model\n",
    "    if uploader_file is None:\n",
    "     # if file is empty, display: please upload file\n",
    "        st.error(\"Please upload a file！\")\n",
    "        return\n",
    "\n",
    "    else:\n",
    "        st.success('Successfully uploaded!')\n",
    "        input_df = pd.read_csv(uploader_file)\n",
    "        input_df.dropna(inplace=True)\n",
    "    \n",
    "\n",
    "    # feature\n",
    "    feature = input_df['Keywords'] # get feature\n",
    "    feature_lists = feature.values.tolist()\n",
    "    \n",
    "    # target\n",
    "    target = input_df['Genre']\n",
    "    target_lists = target.values.tolist()\n",
    "    \n",
    "    # transfrom the feature to numeric features\n",
    "    tf = TfidfVectorizer()\n",
    "\n",
    "\n",
    "    n_feature = tf.fit_transform(feature_lists)\n",
    "    \n",
    "    # split data to training data and test data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(n_feature, target_lists, test_size=0.2, random_state=453)\n",
    "    \n",
    "    # model: MultinomialNB\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(x_train, y_train)\n",
    "    score1 = nb.score(x_test,y_test)\n",
    "    \n",
    "  \n",
    "\n",
    "    st.write(\"## Model score is: \", score1)\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    \n",
    "\n",
    "    # display label names and apperance times\n",
    "    targetvc = target.value_counts()\n",
    "    chart_data=pd.DataFrame(targetvc)\n",
    "    st.bar_chart(chart_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # data display\n",
    "    c = CountVectorizer()\n",
    "    result = c.fit_transform(feature_lists)\n",
    "    feature_names = c.get_feature_names_out()\n",
    "    # use regular expression to deduct some numeric words\n",
    "    filtered_feature_names = [name for name in feature_names if not re.search(r'\\d', name)]\n",
    "    filtered_feature_names = [name for name in filtered_feature_names if len(name) >= 4]\n",
    "\n",
    "    selected_options = st.multiselect('Please select the description:', filtered_feature_names)\n",
    "    st.write('The selected descriptions are:', selected_options)\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "\n",
    "    st.write(\"#### Your current potential movie preferences list：\")\n",
    "\n",
    "    if selected_options:\n",
    "        filtered_data_frames = []\n",
    "\n",
    "        # based on user selection, store the filtered data frames\n",
    "        for option in selected_options:\n",
    "            filtered_rows = input_df[input_df['Keywords'].str.contains(option, case=False)]\n",
    "            if not filtered_rows.empty:\n",
    "                filtered_data_frames.append(filtered_rows)\n",
    "\n",
    "        # Display the latest filtered data frame\n",
    "        if filtered_data_frames:\n",
    "            latest_filtered_frame = filtered_data_frames[-1]\n",
    "            st.write(f\"Length of the filtered data: {len(latest_filtered_frame)}\")\n",
    "            latest_filtered_frame = latest_filtered_frame.iloc[:,1:].reset_index(drop=True)\n",
    "            st.write(latest_filtered_frame)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "     # submission button:\n",
    "    with st.form(\"latest_filtered_frame\"):\n",
    "        \n",
    "        submitted=st.form_submit_button(\"Submit to predict your movie preference\")\n",
    "        if submitted:  \n",
    "          # add progress bar\n",
    "            import time\n",
    "            latest_iteration = st.empty()\n",
    "            bar = st.progress(0)\n",
    "            for i in range(100):\n",
    "                latest_iteration.text(f'Iteration{i+1}')\n",
    "                bar.progress((i+5) % 101)\n",
    "                time.sleep(0.02)\n",
    "\n",
    "            # feature\n",
    "            featureUser = latest_filtered_frame['Keywords']\n",
    "            featureUser_list = featureUser.values.tolist()\n",
    "\n",
    "\n",
    "            # transfrom the feature to numeric features\n",
    "            n_feature = tf.transform(featureUser_list)\n",
    "\n",
    "            # model: MultinomialNB\n",
    "            target_userget = nb.predict(n_feature)\n",
    "            if len(target_userget) > 0:\n",
    "                st.write(\"### Your movie preference is: \", target_userget[0])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # movie remoccendation\n",
    "            st.subheader('Here are top 10 movies you might be interested in:')\n",
    "            selected_rows = input_df[input_df['Genre'] == target_userget[0]]\n",
    "            RecommendedMovies = selected_rows.sort_values('Worldwide Box Office', ascending= False)\n",
    "            columns_to_keep = ['Movie', 'Genre','Languages', 'Worldwide Box Office', 'Running Time' , 'Production Countries','Keywords']\n",
    "            RecommendedMovies = RecommendedMovies[columns_to_keep]\n",
    "            RecommendedMovies_slice = RecommendedMovies.head(10).reset_index(drop=True)\n",
    "            st.dataframe(RecommendedMovies_slice, width = 800)\n",
    "            \n",
    "            \n",
    "            \n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('                            ')\n",
    "    st.write('========================================================================================')\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    ################################################################################# \n",
    "    \n",
    "                                    # Lei Liu\n",
    "        \n",
    "    ################################################################################# \n",
    "    \n",
    "    \n",
    "    st.image('LeiBackground.jpg', width = 700)\n",
    "    st.header('Lei Liu')\n",
    "    # Data Wrangling\n",
    "    st.subheader('Data Wrangling - Dealing with date and time')\n",
    "    code2 = \"\"\"\n",
    "    from sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from wordcloud import WordCloud\n",
    "    \n",
    "    data.Date = data.Date.str.replace(' ', '/',regex=True).str.replace(',', '',regex=True)\n",
    "    data.Date = data.Date.str.replace(\"th\", \"\")\n",
    "    data.Date = data.Date.str.replace(\"st\", \"\")\n",
    "    data.Date = data.Date.str.replace(\"nd\", \"\")\n",
    "    data.Date = data.Date.str.replace(\"rd\", \"\")\n",
    "    data['Date'] = data['Date'].str.split('/').str[0].str[:3]+'/'+data['Date'].str.split('/').str[1]+'/'+data['Date'].str.split('/').str[2]\n",
    "    data = data.dropna(subset=\"Date\")\n",
    "    data.Date = pd.to_datetime(data.Date,format=\"%b/%d/%Y\")\n",
    "\n",
    "    \"\"\"    \n",
    "    st.code(code2, language='python')\n",
    "    \n",
    "    # 1. KNNregression model\n",
    "    st.subheader('Worldwide Box Office Prediction')\n",
    "    \n",
    "    # upload movie csv\n",
    "    uploader_file2 = st.file_uploader(\n",
    "        label = \"Upolad your dataset\"\n",
    "        , key=\"uploader2\"\n",
    "    )\n",
    "    \n",
    "    data = None \n",
    "    \n",
    "   # if the file is uploaded successfully, then go to train model\n",
    "    if uploader_file2 is None:\n",
    "     # if file is empty, display: please upload file\n",
    "        st.error(\"Please upload a file！\")\n",
    "        return\n",
    "\n",
    "    else:\n",
    "        st.success('Successfully uploaded!')\n",
    "        data = pd.read_csv(uploader_file2)\n",
    "        data.dropna(inplace=True)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # data processing\n",
    "    data.Date = data.Date.str.replace(' ', '/',regex=True).str.replace(',', '',regex=True)\n",
    "    data.Date = data.Date.str.replace(\"th\", \"\")\n",
    "    data.Date = data.Date.str.replace(\"st\", \"\")\n",
    "    data.Date = data.Date.str.replace(\"nd\", \"\")\n",
    "    data.Date = data.Date.str.replace(\"rd\", \"\")\n",
    "    data['Date'] = data['Date'].str.split('/').str[0].str[:3]+'/'+data['Date'].str.split('/').str[1]+'/'+data['Date'].str.split('/').str[2]\n",
    "    data = data.dropna(subset=\"Date\")\n",
    "    data.Date = pd.to_datetime(data.Date,format=\"%b/%d/%Y\")\n",
    "    data['Month'] = data['Date'].dt.month\n",
    "    \n",
    "    # data cleaning, remove the data have no Genre infomation \n",
    "    data.dropna(subset='Genre',inplace=True)\n",
    "    \n",
    "    \n",
    "    # fig 1\n",
    "    st.write(\"fig 1 - Top 10 Genres Movies Count \")\n",
    "     # display label names and apperance times\n",
    "    def plot_genre_counts(data):\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        genre_counts = data['Genre'].value_counts()[:10].sort_values(ascending=False)\n",
    "        ax = sns.countplot(y='Genre', data=data[data['Genre'].isin(genre_counts.index)], order=genre_counts.index, palette='hls')\n",
    "        for i, count in enumerate(genre_counts.values):\n",
    "            ax.text(count, i, str(count), ha='right', va='center', color='white', fontweight='bold')\n",
    "        ax.set_title('Top 10 Genres Movies Count')\n",
    "        ax.set_xlabel('Count')\n",
    "        ax.set_ylabel('Genre')\n",
    "        return fig\n",
    "\n",
    "    st.title('Top 10 Genres Movies Count')\n",
    "    fig = plot_genre_counts(data)\n",
    "    st.pyplot(fig)\n",
    "    st.write('Through our analysis of the Worldwide Box Office, we have discovered that while Drama genre has the most movies produced, Action movies are the most popular, closely followed by Adventure genre.')\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "#   fig 2\n",
    "    st.write('fig 2 - Top 10 Genre Worldwide Box Office (Log Scale)')\n",
    "    data_group=data[['Worldwide Box Office','Genre']].groupby('Genre').sum()\n",
    "    box_office_log = np.log10(data_group['Worldwide Box Office'])\n",
    "    sns.set_style('whitegrid')\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    ax = sns.barplot(x=box_office_log, y=data_group.index, data=data_group)\n",
    "\n",
    "    plt.title('Top 10 Genre Worldwide Box Office (Log Scale)')\n",
    "    plt.xlabel('Box Office (Log Scale)')\n",
    "    plt.ylabel('Genre')\n",
    "\n",
    "    for i, v in enumerate(box_office_log):\n",
    "        ax.text(v, i, '{:.2f}'.format(v), ha='right', va='center',color='white', weight='bold')\n",
    "    \n",
    "    st.title('Top 10 Genre Worldwide Box Office')\n",
    "    st.pyplot(plt)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "   # fig 3\n",
    "    st.write('fig 3 - Scatter Plot Matrix')\n",
    "#     sns.set_style('whitegrid')\n",
    "\n",
    "#     # Create scatter plot matrix\n",
    "    box_office_df = data[['Domestic Box Office','International Box Office','Production Budget','Running Time','Genre','Month']]\n",
    "#     sns.pairplot(box_office_df, vars=['Domestic Box Office', 'International Box Office', 'Production Budget', 'Running Time', 'Month'], hue='Genre')\n",
    "\n",
    "#     # Show the plot\n",
    "#     plt.show()\n",
    "    st.title('Scatter Plot Matrix')\n",
    "#     st.pyplot(plt)\n",
    "    st.image('LeiLiufig 3 - Scatter Plot Matrix.png')\n",
    "\n",
    " \n",
    "    \n",
    "    st.write('Upon analyzing the pairplots, it becomes evidentno significant correlations betw that there are een the running time and other variables.')\n",
    "    box_office_df = box_office_df.drop(columns=['Running Time','Month'])\n",
    "    box_office_df = pd.get_dummies(box_office_df,columns=['Genre'])\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    ### R2 and RMSE\n",
    "    st.write('fig 4 - RSquare for the KNeighborsRegressorlots and RMSE for the KNeighborsRegressor')\n",
    "    st.image(\"LeiLiuRSquare_fig4.png\")\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_df = pd.DataFrame(scaler.fit_transform(box_office_df), columns=box_office_df.columns)\n",
    "    X = scaled_df.drop('International Box Office', axis=1)\n",
    "    y = box_office_df['International Box Office']\n",
    "\n",
    "    # train model\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "#     knn = KNeighborsRegressor(n_neighbors=5, weights='uniform')\n",
    "#     mod = knn.fit(X, y)\n",
    "\n",
    "#     # predict\n",
    "#     x = X + 0.0001\n",
    "#     y_hat = mod.predict(x)\n",
    "\n",
    "#     # calculate calculate_regression_goodness_of_fit\n",
    "#     def calculate_regression_goodness_of_fit(ys, y_hat):\n",
    "#         ss_total = np.sum(np.square(ys - np.mean(ys)))\n",
    "#         ss_residual = np.sum(np.square(ys - y_hat))\n",
    "#         ss_regression = np.sum(np.square(y_hat - np.mean(ys)))\n",
    "\n",
    "#         r_square = ss_regression / ss_total\n",
    "#         rmse = np.sqrt(ss_residual / float(len(ys)))\n",
    "\n",
    "#         return r_square, rmse\n",
    "\n",
    "#     calculate_regression_goodness_of_fit(y, y_hat)\n",
    "\n",
    "#     rsquare_arr = []\n",
    "#     rmse_arr = []\n",
    "\n",
    "#     for k in range(2, 200):\n",
    "#         knn = KNeighborsRegressor(n_neighbors=k)\n",
    "#         y_hat = knn.fit(X, y).predict(x)\n",
    "#         rsquare, rmse = calculate_regression_goodness_of_fit(y, y_hat)\n",
    "#         rmse_arr.append(rmse)\n",
    "#         rsquare_arr.append(rsquare)\n",
    "\n",
    "#     # subplots\n",
    "#     fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 8))\n",
    "\n",
    "#     # RSquare\n",
    "#     axes[0].plot(range(2, 200), rsquare_arr, c='k', label='R Square')\n",
    "#     axes[0].axis('tight')\n",
    "#     axes[0].set_xlabel('k number of nearest neighbors')\n",
    "#     axes[0].set_ylabel('RSquare')\n",
    "#     axes[0].legend(loc='upper right')\n",
    "#     axes[0].set_title(\"RSquare for the KNeighborsRegressor\")\n",
    "\n",
    "#     # RMSE\n",
    "#     axes[1].plot(range(2, 200), rmse_arr, c='k', label='RMSE')\n",
    "#     axes[1].axis('tight')\n",
    "#     axes[1].set_xlabel('k number of nearest neighbors')\n",
    "#     axes[1].set_ylabel('RMSE')\n",
    "#     axes[1].legend(loc='upper left')\n",
    "#     axes[1].set_title(\"RMSE for the KNeighborsRegressor\")\n",
    "\n",
    "#     # adjust space between each plot\n",
    "#     plt.subplots_adjust(hspace=0.5)\n",
    "    \n",
    "    # show plot\n",
    "#     st.pyplot(fig)\n",
    "   \n",
    "\n",
    "    st.write('Based on the above plots, it seems that a K value between 0 and 5 yields a higher RSquare score and a lower RMSE score, indicating a better fit for the model.')\n",
    "    \n",
    "    # fit the best K value by performing cross-validation for each K value\n",
    "    k_values = range(1, 11)\n",
    "\n",
    "    best_k = None\n",
    "    best_mse = np.inf\n",
    "\n",
    "    # Perform cross-validation for each K value\n",
    "    for k in k_values:\n",
    "        # Train a KNN regression model\n",
    "        model = KNeighborsRegressor(n_neighbors=k)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the testing set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate mean squared error\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "        # Check if current K value is the best\n",
    "        if mse < best_mse:\n",
    "            best_k = k\n",
    "            best_mse = mse\n",
    "\n",
    "    st.write(f\"Best K value: {best_k}\")\n",
    "    \n",
    "\n",
    "    \n",
    "    # fit model\n",
    "    opt_knn = KNeighborsRegressor(n_neighbors=best_k)\n",
    "    opt_knn.fit(X_train, y_train)\n",
    "    y_pred = opt_knn.predict(X_test)\n",
    "    accuracy = opt_knn.score(X_test, y_test)\n",
    "    st.write(\"## Model accuracy: \", accuracy)\n",
    "    \n",
    "    \n",
    "\n",
    "     # 1. Genre\n",
    "    genre_options = data['Genre'].unique()\n",
    "    genre = st.selectbox('Choose a genre:', genre_options)\n",
    "    submitted = False\n",
    "\n",
    "    with st.form('userinput2'):\n",
    "        # 2. Production Budget\n",
    "        productionBudget = st.number_input(label = 'Production Budget($)',min_value = 0)\n",
    "        # 3. Domestic Box Office\n",
    "        domesticBoxOffice = st.number_input(label = 'Domestic Box Office($)', min_value = 0)\n",
    "        st.write(\"### User Input：{}\".format([genre, productionBudget, domesticBoxOffice]))\n",
    " \n",
    "        # submission button\n",
    "        submitted2 = st.form_submit_button(\"Submit to predict International Box Office\")\n",
    " \n",
    "        \n",
    "#        if submitted:\n",
    "        if submitted2:\n",
    "        # preprocess 'Genre' by performing ont-hot (14)\n",
    "            genre_Action, genre_Adventure, genre_Drama, genre_Thriller_Suspense, genre_Comedy, genre_Western, genre_Musical, genre_BlackComedy, genre_Horror, genre_RomanticComedy, genre_Documentary, genre_Concert_Performance, genre_Reality, genre_MultipleGenres, = 0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
    "            if genre == 'Action':\n",
    "                genre_Action = 1\n",
    "            elif genre == 'Adventure':\n",
    "                genre_Adventure = 1\n",
    "            elif genre == 'Drama':\n",
    "                genre_Drama = 1\n",
    "            elif genre == 'genre_Thriller/Suspense':\n",
    "                genre_Thriller_Suspense = 1\n",
    "            elif genre == 'Comedy':\n",
    "                genre_Comedy = 1\n",
    "            elif genre == 'Western':\n",
    "                genre_Western = 1\n",
    "            elif genre == 'Musical':\n",
    "                genre_Musical = 1\n",
    "            elif genre == 'Black Comedy':\n",
    "                 genre_BlackComedy = 1\n",
    "            elif genre == 'Horror':\n",
    "                genre_Horror = 1\n",
    "            elif genre == 'Romantic Comedy':\n",
    "                genre_RomanticComedy = 1\n",
    "            elif genre == 'Documentary':\n",
    "                genre_Documentary = 1\n",
    "            elif genre == 'Concert/Performance':\n",
    "                genre_Concert_Performance = 1\n",
    "            elif genre == 'Reality':\n",
    "                genre_Reality = 1\n",
    "            elif genre == 'Multiple Genres':\n",
    "                genre_MultipleGenres = 1\n",
    "\n",
    "            # combie all features together\n",
    "            temp_feature = [\n",
    "                 productionBudget, \n",
    "                 domesticBoxOffice,\n",
    "                 genre_Action, \n",
    "                 genre_Adventure,\n",
    "                 genre_Drama, \n",
    "                 genre_Thriller_Suspense, \n",
    "                 genre_Comedy, \n",
    "                 genre_Western, \n",
    "                 genre_Musical,\n",
    "                 genre_BlackComedy, \n",
    "                 genre_Horror,\n",
    "                 genre_RomanticComedy,\n",
    "                 genre_Documentary, \n",
    "                 genre_Concert_Performance, \n",
    "                 genre_Reality, \n",
    "                 genre_MultipleGenres]\n",
    "            \n",
    "            st.write(str(temp_feature))\n",
    "\n",
    "\n",
    "            # predict\n",
    "            # The International Box Office:\n",
    "            predUser = opt_knn.predict([temp_feature])\n",
    "            formatted_predUser = np.array2string(predUser, formatter={'float_kind': lambda x: '{:,.0f}'.format(x)})\n",
    "            st.write('## The International Box Office is around($): ' , str(formatted_predUser))\n",
    "           \n",
    "            # The Global Box Office:\n",
    "            globalBox_predUser = predUser + domesticBoxOffice\n",
    "            formatted_globalBox_predUser = np.array2string(globalBox_predUser, formatter={'float_kind': lambda x: '{:,.0f}'.format(x)})\n",
    "            st.write('## The Global Box Office is around($): ' , str(formatted_globalBox_predUser))\n",
    "            \n",
    "            \n",
    "            # Return on Investment\" -> \"ROI\"\n",
    "            ROI = (globalBox_predUser -productionBudget)/productionBudget\n",
    "            formatted_ROI = np.array2string(ROI, formatter={'float_kind': lambda x: '{:,.0f}'.format(x)})\n",
    "            \n",
    "            st.write('## Return on Investment(ROI):', str(formatted_ROI))\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d029a6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: altair_viewer in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (0.4.0)\n",
      "Requirement already satisfied: altair-data-server>=0.4.0 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from altair_viewer) (0.4.1)\n",
      "Requirement already satisfied: altair in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from altair_viewer) (4.2.2)\n",
      "Requirement already satisfied: tornado in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from altair-data-server>=0.4.0->altair_viewer) (6.1)\n",
      "Requirement already satisfied: portpicker in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from altair-data-server>=0.4.0->altair_viewer) (1.5.2)\n",
      "Requirement already satisfied: toolz in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from altair->altair_viewer) (0.11.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from altair->altair_viewer) (4.16.0)\n",
      "Requirement already satisfied: entrypoints in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from altair->altair_viewer) (0.4)\n",
      "Requirement already satisfied: pandas>=0.18 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from altair->altair_viewer) (1.4.4)\n",
      "Requirement already satisfied: numpy in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from altair->altair_viewer) (1.21.5)\n",
      "Requirement already satisfied: jinja2 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from altair->altair_viewer) (2.11.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from jsonschema>=3.0->altair->altair_viewer) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from jsonschema>=3.0->altair->altair_viewer) (21.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.18->altair->altair_viewer) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.18->altair->altair_viewer) (2022.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from jinja2->altair->altair_viewer) (2.0.1)\n",
      "Requirement already satisfied: psutil in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from portpicker->altair-data-server>=0.4.0->altair_viewer) (5.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=0.18->altair->altair_viewer) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install altair_viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec5fc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: squarify in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (0.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install squarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aab46fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (1.9.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from wordcloud) (1.21.5)\n",
      "Requirement already satisfied: matplotlib in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from wordcloud) (3.5.2)\n",
      "Requirement already satisfied: pillow in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from wordcloud) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c874654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /Users/hanhan/opt/anaconda3/lib/python3.9/site-packages (9.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15bdf355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3fb635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.1.101:8501\u001b[0m\n",
      "\u001b[0m\n",
      "/Users/hanhan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/hanhan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/hanhan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/hanhan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/hanhan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2023-05-28 11:18:30.964 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hanhan/opt/anaconda3/lib/python3.9/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 565, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"/Users/hanhan/project3/AllaboutMovies_app.py\", line 970, in <module>\n",
      "    main()\n",
      "  File \"/Users/hanhan/project3/AllaboutMovies_app.py\", line 468, in main\n",
      "    st.wirte(\"#### Your current potential movie preferences list：\")\n",
      "AttributeError: module 'streamlit' has no attribute 'wirte'\n",
      "/Users/hanhan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/hanhan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/hanhan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!streamlit run AllaboutMovies_app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc6816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
